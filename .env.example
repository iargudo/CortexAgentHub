# ==========================================
# CortexAgentHub - Environment Variables Example
# ==========================================
# Copy this file to .env and fill in your values

# ==========================================
# DATABASE CONFIGURATION (PostgreSQL)
# ==========================================
# Note: Database name should be 'cortexagenthub' (no underscore)
DB_HOST=localhost
DB_PORT=5432
DB_NAME=cortexagenthub
DB_USER=postgres
DB_PASSWORD=postgres

# ==========================================
# REDIS CONFIGURATION
# ==========================================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# ==========================================
# MCP SERVER CONFIGURATION
# ==========================================
MCP_SERVER_PORT=8099
MCP_CONTEXT_TTL=3600
MCP_MAX_TOOL_EXECUTIONS=10

# ==========================================
# API SERVER CONFIGURATION
# ==========================================
API_PORT=3000
API_HOST=0.0.0.0

# ==========================================
# ADMIN FRONTEND CONFIGURATION
# ==========================================
VITE_API_BASE_URL=http://localhost:3000

# ==========================================
# LLM PROVIDERS
# ==========================================
# Configure one or more LLM providers
# Orchestration flows will specify which provider/model to use

# OpenAI (Recommended for production)
# Get API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=2000

# Anthropic Claude
# Get API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_MAX_TOKENS=4000

# Google Gemini
# Get API key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_MODEL=gemini-pro
GOOGLE_TEMPERATURE=0.7
GOOGLE_MAX_TOKENS=2048

# Ollama (Local - Free, No API key needed)
# Install from: https://ollama.ai/
# Popular models: llama3.2:latest, llama3:8b, mistral:latest, gpt-oss:20b
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:latest
OLLAMA_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=2000

# HuggingFace
# Get API key from: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=your_huggingface_api_key_here
HUGGINGFACE_MODEL=mistralai/Mixtral-8x7B-Instruct-v0.1
HUGGINGFACE_TEMPERATURE=0.7
HUGGINGFACE_MAX_TOKENS=1000

# ==========================================
# WHATSAPP CONFIGURATION (UltrMsg)
# ==========================================
# Get your credentials from: https://ultramsg.com/dashboard
# 
# Note: For multi-instance (multiple WhatsApp numbers):
# - Configure each number in the Admin UI under "Channels"
# - Use the instance_identifier to route messages to specific agents
# - The webhook URL is shared: http://your-domain/webhooks/whatsapp
#
WHATSAPP_PROVIDER=ultramsg
WHATSAPP_ULTRAMSG_INSTANCE_ID=your_instance_id
WHATSAPP_ULTRAMSG_TOKEN=your_ultramsg_token
WHATSAPP_PHONE_NUMBER=your_whatsapp_number
WHATSAPP_WEBHOOK_URL=https://your-domain.com/webhooks/whatsapp

# Optional: Webhook secret for security (generate with: openssl rand -hex 32)
# Leave commented out if UltrMsg doesn't send a secret in the payload
# WHATSAPP_WEBHOOK_SECRET=your_random_secret_token

# Alternative: Twilio WhatsApp Configuration
# WHATSAPP_PROVIDER=twilio
# WHATSAPP_ULTRAMSG_TOKEN=your_auth_token
# WHATSAPP_ULTRAMSG_INSTANCE_ID=your_account_sid
# WHATSAPP_PHONE_NUMBER=+1234567890
# WHATSAPP_WEBHOOK_URL=https://your-domain.com/webhooks/whatsapp

# ==========================================
# TELEGRAM CONFIGURATION
# ==========================================
# Get your bot token from: https://t.me/BotFather
TELEGRAM_BOT_TOKEN=your_telegram_bot_token
TELEGRAM_WEBHOOK_URL=https://your-domain.com/webhooks/telegram

# ==========================================
# LEADBOX CONFIGURATION
# ==========================================
# Get your API token from: https://leadbox.ec/
# Used by send_leadbox_lead tool for lead capture
LEADBOX_API_TOKEN=your_leadbox_token_here

# ==========================================
# EMAIL CONFIGURATION
# ==========================================
# SMTP Configuration (for email-type tools)
# Email-type tools can now use SMTP directly without JavaScript code
# Configure SMTP settings in the tool config in Admin UI
# Note: The code uses EMAIL_SMTP_PASS (not EMAIL_SMTP_PASSWORD)
EMAIL_SMTP_HOST=smtp.gmail.com
EMAIL_SMTP_PORT=587
EMAIL_SMTP_SECURE=false
EMAIL_SMTP_USER=your_email@gmail.com
EMAIL_SMTP_PASS=your_app_password
EMAIL_FROM_NAME=CortexAgentHub Bot

# Email webhook (for receiving emails)
EMAIL_WEBHOOK_URL=https://your-domain.com/webhooks/email

# Note: For email-type tools:
# - Set tool_type to 'email' in the Admin UI
# - Configure SMTP settings in the tool's config field (JSON)
# - No JavaScript implementation needed for email tools
# - Other tool types (javascript) still use code snippets

# ==========================================
# WEBCHAT CONFIGURATION
# ==========================================
# WebSocket server for the Playground and test clients
# Supports multi-instance: different websites can have different agents
# by including 'websiteId' in the JWT token
WEBCHAT_WS_PORT=3078
WEBCHAT_ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5174

# Note: For multi-instance WebChat:
# 1. Configure multiple channel_configs with different instance_identifier
# 2. Generate JWT with: { userId: 'user123', websiteId: 'corporate' }
# 3. WebChatAdapter extracts websiteId and routes to appropriate agent
# Example: Corporate site uses 'corporate', Shop uses 'shop', etc.

# ==========================================
# SECURITY
# ==========================================
# JWT Secret for authentication
# Generate with: openssl rand -hex 32
JWT_SECRET=your_jwt_secret_here

# ==========================================
# LOGGING
# ==========================================
LOG_LEVEL=info

# ==========================================
# DEVELOPMENT
# ==========================================
NODE_ENV=development

# For ngrok or local development (for webhook testing)
# PUBLIC_URL=https://xyz123.ngrok.io

# ==========================================
# QUICK START CHECKLIST
# ==========================================
# 1. Copy this file:          cp env.example.txt .env
# 2. Update DB_NAME to:       cortexagenthub (no underscore!)
# 3. Configure at least ONE LLM provider (Ollama is easiest for local)
# 4. Run setup:               ./setup-local.sh
# 5. Start services:          pnpm dev
# 6. Access Admin UI:         http://localhost:5174
# 7. Access API:              http://localhost:3000
# 8. Test Playground:         http://localhost:5174/playground
#
# ==========================================
# PORTS REFERENCE
# ==========================================
# 3000  - API Service (Backend)
# 3078  - WebChat WebSocket Server
# 5174  - Admin Frontend (Vite dev server)
# 5432  - PostgreSQL Database
# 6379  - Redis
# 11434 - Ollama (if using local LLM)
#
# ==========================================
# TROUBLESHOOTING
# ==========================================
# Database issues:
#   - Verify: psql -U postgres -d cortexagenthub -c "SELECT 1"
#   - Recreate: dropdb cortexagenthub && createdb cortexagenthub && ./setup-local.sh
#
# Redis issues:
#   - Check: redis-cli ping
#   - Should return: PONG
#
# Port conflicts:
#   - Find process: lsof -ti:PORT
#   - Kill process: lsof -ti:PORT | xargs kill -9
#
# Ollama not responding:
#   - Check status: curl http://localhost:11434/api/tags
#   - Pull model: ollama pull llama3.2:latest
#
